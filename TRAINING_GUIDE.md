# ğŸš€ Traffic Buddy - Training Guide

HÆ°á»›ng dáº«n chi tiáº¿t Ä‘á»ƒ cháº¡y training cho production.

## ğŸ“‹ YÃªu cáº§u

- **GPU**: 2x A100 40GB (recommended) hoáº·c 1x A100 80GB
- **Python**: 3.10+
- **Dependencies**: ÄÃ£ cÃ i Ä‘áº·t qua `requirements.txt`

## ğŸ¯ CÃ¡c cÃ¡ch training

### 1. **Training vá»›i Ray Tune (Recommended cho Production)**

Tá»± Ä‘á»™ng tÃ¬m kiáº¿m hyperparameters tá»‘t nháº¥t:

```bash
# Cháº¡y vá»›i cáº¥u hÃ¬nh máº·c Ä‘á»‹nh
bash scripts/train_production.sh

# Hoáº·c custom configuration
BASE_MODEL="Qwen/Qwen3-VL-8B-Instruct" \
NUM_SAMPLES=10 \
NUM_GPUS=2 \
bash scripts/train_production.sh
```

**CÃ¡c tham sá»‘ cÃ³ thá»ƒ override:**
- `BASE_MODEL`: Base model ID (default: Qwen/Qwen3-VL-8B-Instruct)
- `OUTPUT_DIR`: NÆ¡i lÆ°u checkpoints (default: ./checkpoints/lora_sft)
- `WANDB_PROJECT`: WandB project name (default: zalo_challenge)
- `NUM_SAMPLES`: Sá»‘ lÆ°á»£ng trials Ä‘á»ƒ tune (default: 8)
- `NUM_GPUS`: Sá»‘ GPU sá»­ dá»¥ng (default: 2)

### 2. **Training Manual (Single Trial)**

Cháº¡y trá»±c tiáº¿p vá»›i Python:

```bash
cd /home/quanpv/project/traffic_buddy

python src/training/train.py \
    --base_model_id "Qwen/Qwen3-VL-8B-Instruct" \
    --output_dir "./checkpoints/lora_sft_manual" \
    --wandb_project "zalo_challenge" \
    --num_samples 1
```

### 3. **Training Simple (KhÃ´ng dÃ¹ng Ray Tune)**

Sá»­ dá»¥ng script Ä‘Æ¡n giáº£n hÆ¡n, phÃ¹ há»£p cho testing:

```bash
python src/training/train_simple.py \
    --base_model_id "Qwen/Qwen3-VL-8B-Instruct" \
    --output_dir "./checkpoints/lora_simple" \
    --learning_rate 2e-4 \
    --num_epochs 3 \
    --lora_rank 256 \
    --batch_size 1 \
    --grad_accum_steps 4
```

## ğŸ“Š Monitoring Training

### WandB Dashboard
Tá»± Ä‘á»™ng log vÃ o WandB, xem táº¡i:
```
https://wandb.ai/your-username/zalo_challenge
```

### Local Logs
Xem log files trong:
```bash
tail -f outputs/logs/training_*.log
```

### Ray Tune Results
Xem progress Ray Tune:
```bash
cd ray_results/training
tensorboard --logdir .
```

## ğŸ“ Cáº¥u trÃºc Output

```
checkpoints/
â””â”€â”€ lora_sft/
    â””â”€â”€ trial_lr0.0002_r128/
        â”œâ”€â”€ checkpoint-200/     # Intermediate checkpoint
        â”œâ”€â”€ checkpoint-400/     # ...
        â”œâ”€â”€ checkpoint-600/
        â”œâ”€â”€ checkpoint-800/
        â”œâ”€â”€ checkpoint-1000/
        â”œâ”€â”€ best/               # Best model (lowest eval_loss)
        â””â”€â”€ final/              # Final model
```

## âš™ï¸ Hyperparameters Die

Ray Tune sáº½ tá»± Ä‘á»™ng tÃ¬m kiáº¿m:

| Parameter | Search Space |
|-----------|--------------|
| Learning Rate | loguniform(1e-5, 5e-4) |
| LoRA Rank | [64, 128, 256] |
| LoRA Alpha | [16, 32] |
| LoRA Dropout | [0.05, 0.1] |
| Num Epochs | [1, 2, 3] |
| Batch Size | [1, 2] |
| Grad Accum | [4, 8] |
| Weight Decay | [0.0, 0.01, 0.1] |
| LR Scheduler | [cosine, linear, polynomial] |
| Early Stopping | [False, True] |
| Early Stopping Patience | [3, 5, 7] |

## ğŸ”¥ Optimizations Applied

### Training Stability
- âœ… Gradient clipping (max_grad_norm=1.0)
- âœ… Weight decay regularization
- âœ… Mixed precision training (bf16)

### Overfitting Prevention
- âœ… Early stopping callback
- âœ… Validation-based best model selection
- âœ… L2 regularization

### Training Efficiency
- âœ… Gradient checkpointing
- âœ… 4-bit quantization (optional)
- âœ… Ray Tune for hyperparameter search

### Model Quality
- âœ… Load best model at end
- âœ… Save based on eval_loss
- âœ… Multiple checkpoint saves

## ğŸ“ Step-by-step Production Training

### Step 1: Prepare Environment
```bash
# Activate virtual environment
source .venv/bin/activate  # or your venv path

# Check GPU
nvidia-smi
```

### Step 2: Verify Dataset
```bash
# Check dataset exists
ls datasets/traffic_dataset/

# If not, build it
python src/data/dataset_builder.py
```

### Step 3: Start Training
```bash
# Production training vá»›i Ray Tune
bash scripts/train_production.sh
```

### Step 4: Monitor Progress
```bash
# Terminal 1: Watch logs
tail -f outputs/logs/training_*.log

# Terminal 2: Watch GPU
watch -n 5 nvidia-smi

# Browser: WandB dashboard
# https://wandb.ai/your-username/zalo_challenge
```

### Step 5: Check Results
```bash
# List all checkpoints
find checkpoints/lora_sft -name "best" -type d

# Evaluate best model
python src/evaluation/eval_vllm.py \
    --model_path checkpoints/lora_sft/trial_*/best
```

## ğŸ› Troubleshooting

### Out of Memory (OOM)
- Giáº£m `batch_size` trong code
- Giáº£m `max_length` (hiá»‡n táº¡i 1024)
- Enable `use_4bit=True` trong search space

### Training Too Slow
- Giáº£m `num_samples` (sá»‘ trials)
- TÄƒng rÃ¡ batch size náº¿u memory cho phÃ©p
- Disable early stopping cho vÃ i trials Ä‘áº§u

### No Improvement
- TÄƒng learning rate range
- TÄƒng number of epochs
- Check data quality

## ğŸ“ Support

Náº¿u gáº·p váº¥n Ä‘á»:
1. Check log files trong `outputs/logs/`
2. Check Ray Tune errors trong `ray_results/`
3. Check WandB logs
4. Verify GPU memory: `nvidia-smi`

## ğŸ¯ Expected Training Time

- **Single Trial**: ~2-4 hours (tÃ¹y vÃ o sá»‘ epochs vÃ  GPU)
- **Ray Tune (8 trials)**: ~16-32 hours vá»›i 2 GPU

## ğŸ“ˆ Expected Results

Vá»›i training tá»‘t, báº¡n nÃªn tháº¥y:
- Training loss giáº£m dáº§n vÃ  á»•n Ä‘á»‹nh
- Eval loss tháº¥p hÆ¡n training loss (no overfitting)
- Best model Ä‘Æ°á»£c lÆ°u trong `best/` folder
- WandB dashboard hiá»ƒn thá»‹ metrics tá»‘t

